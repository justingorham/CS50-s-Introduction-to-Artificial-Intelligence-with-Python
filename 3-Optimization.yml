current location: 
Optimization: choosing the best option form a set of options
local search:
  - search algorithms that maintain a single node and searches by moving to a neighboring node
  - most applicable when we don't care about the path, just the solution
  - example how to place 2 hospitals in a map so that distance between any house to a hospital is minimized
state-space landscape:
  - all possible configurations of state, and a function that gives the cost of any state
  - global maximum: a single state whose value is higher than all of the other states
  - objective function: the function we're trying to maximize
  - global minimum: a single state whose value is lower than all of the other states
  - cost function: the function we're trying to minimize
  - current state: self explanatory
  - neighbors: any node/state 1 step away from current state
Hill Climbing:
  - a local search algorithm
  - start at a state, consider the neighbors of the state. pick the highest neighbor. repeat until all neighbors are lower in value
  - same for a global minimum
  - function HILL-CLIMB(problem):
      - current = initial state of problem
      - repeat:
          - neighbor = highest valued neighbor of current
          - if neighbor not better than current:
              - return current
          - current = neighbor
  - might not always give you optimal solution. May end up with local maxima/minimum
  - flat local maximum could occur as well.
  - shoulder (flat area that's not a local max or min) may be encountered as well.
Hill Climbing Variants:
  Variant: Definition
  steepest-ascent: choose the highest-valued neighbor
  stochastic: choose randomly from higher-valued neighbors
  first-choice: choose the first higher-valued neighbor
  random-restart: conduct hill climbing multiple times
  local beam search: chooses the k highest-valued neighbors
Simulated Annealing:
  - simulating a high temperature system cooling into the solution
  - Early on, higher "temperature": more likely to accept neighbors that are worse than current state
  - Later on, lower "temperature": less likely to accept neighbors that are worse than current state
  - function SIMULATED-ANNEALING(problem, max):
      - current  = initial state of the problem
      - for t = 1 to max:
          - T = Temperature(t)
          - neighbor = random neighbor of current
          - ΔE = how much better neighbor is than current
          - if ΔE > 0:
              - current = neighbor
          - with probability e^{ΔE/T} set current = neighbor
      - return current
Traveling Salesman Problem:
  - computationally difficult
  - NP-Complete problem
  - one definition of a neighbor is switching 2 edges to (remove them and put them between the nodes that weren't connected)
Linear Programming:
  - Minimize a cot function (c_1)(x_1)+(c_2)(x_2)+...+(c_n)(x_n)
  - With constraints of form (a_1)(x_1)+(a_2)(x_2)+...+(a_n)(x_n)≤b or of form (a_1)(x_1)+(a_2)(x_2)+...+(a_n)(x_n)=b
  - with bounds for each variable (l_i)≤(x_i)≤(u_i)
Linear Program Algorithms:
  - Simplex
  - Interior-Point
Constraint Satisfaction:
  - we have some number of variable that need to take on values, but those variables are subject to constraints
  - constraint graph: nodes are variables, edges are a constraints
Constraint Satisfaction Problem:
  - Set of variables {X1,X2,...,Xn}
  - Set of domains for each variable {D1,D2,...,Dn}
  - Set of constraints C
hard constraints: constraints that must be satisfied in a correct solution
soft constraints: constraints that express some notion of which solutions are preferred over others
hard constraints details:
  - unary constraints: constraint involving only one variable
  - binary constraint: 2 variables
  - node consistency: when all the values in a variable's domain satisfy the variable's unary constraints
arc consistency:
  - when all the values in a variable's domain satisfy the variable's binary constraints
  - to make X arc-consistent with respect to Y, remove elements from X's domain until every choice for X has a possible choice for Y
Arc Consistency:
  - function REVISE(csp, X,Y):
      - revised = false
      - for x in X.domain:
          - if no y in Y.domain satisfies constraint for (X,Y):
              - delete x from X.domain
              - revised = true
      - return revised
  - function AC-3(csp):
      - queue = all arcs in csp
      - while queue non-empty:
          - (X,Y) = DEQUEUE(queue)
          - if REVISE(csp,X,Y):
              - if size of X.domain === 0:
                  - return false
              - for each Z in X.neighbors - {Y}:
                  - ENQUEUE(queue,(Z,X))
      - return true
Recall Search Problems:
  - initial state
  - actions
  - transition model
  - goal test
  - path cost function
CSPs as Search Problems:
  - initial state: empty assignment (no variables)
  - actions: add a {variable = value} to assignment
  - transition model: shows how adding an assignment changes the assignment
  - goal test: check if all variables assigned and constraints all satisfied
  - path cost function: all paths have same cost
Backtracking Search:
  - make assignments from variables to values. If we get stuck, we'll backtrack and try something else
  - function BACKTRACK(assignment, csp):
    - if assignment complete: return assignment
    - var = SELECT-UNASSIGNED-VAR(assignment,csp)
    - for value in DOMAIN-VALUES(var,assignment,csp):
      - if value consistent with assignment:
        - add {var = value} to assignment
        - result = BACKTRACK(assignment, csp)
        - if result ≠ failure: return result
      - remove {var = value} from assignment
    - return failure
maintaining arc-consistency:
  - algorithm for enforcing arc-consistency every time we make a new assignment
  - When we make a new assignment to X, calls AC-3, starting with a queue of all arcs (Y,X) where Y is a neighbor of X
  - function BACKTRACK(assignment, csp):
    - if assignment complete: return assignment
    - var = SELECT-UNASSIGNED-VAR(assignment,csp)
    - for value in DOMAIN-VALUES(var,assignment,csp):
      - if value consistent with assignment:
        - add {var = value} to assignment
        - inferences = INFERENCE(assignment, csp)
        - if inferences ≠ failure: add inferences to assignment
        - result = BACKTRACK(assignment, csp)
        - if result ≠ failure: return result
      - remove {var = value} and inferences from assignment
    - return failure
SELECT-UNASSIGNED-VAR:
  - minimum remaining values (MRV) heuristic: select the variable that has the smallest domain
  - degree heuristic: 
    - select the variable that has the highest degree
    - degree: number of nodes attached to (constrained by) the node in question
DOMAIN-VALUES:
  - least-constraining values heuristic: return variables in order by number of choices that are ruled out for neighboring variables
  -
    - try least-constraining values first
