Current Place: 
Supervised Learning: given a data set of input-output pairs, learn a function to map inputs to outputs
classification: supervised learning task of learning a function mapping an input point to a discrete category
example:
  - given data where we have humidity and pressure for each day, if we label each pinot as "rain" or "no rain", the applied label makes this supervised
  - f(humidity,pressure) to give us "Rain" or "No Rain".
  - we want to approximate f, so we come up with a hypothesis function h(humidity, pressure)
  - we could plot the points in a 2 axis graph (n-axis if we have n variables)
  - given our data, if given a new point, we want to predict classification
nearest-neighbor classification: algorithm that, given an input, chooses the class of the nearest data point to that input
k-nearest neighbor classification:
  - algorithm that, given an input, chooses the most common class out of the k nearest data points to that input
  - can be slow in finding neighbors
we could try to find a line that separate categories:
  - data isn't always that clean however.
back to example:
  - x_{1} = humidity
  - x_{2} = pressure
  - h(x_1, x_2) =:
      - Rain if w_0 + (w_1)(x_1) + (w_1)(x_1) ≥ 0
      - No Rain otherwise
  - to keep things in math terms, Rain = 1 and No Rain =
  - Weight Vector w: (w_0, w_1, w_2)
  - Input vector x: (1, x_1, x_2)
  - a data point is now the dot product of Weight Vector and Input Vector
  - h_{w}(x) =:
      - 1 if w · x ≥ 0
      - 0 otherwise
perceptron learning rule:
  - Given data point (x,y), update each weight according to:
      - w_{i} = w_{i} + α(y - h_{w}(x)) × x_{i}
      - w_{i} = w_{i} + α(actual value - estimate) × x_{i}
hard threshold:
  - definitely puts points into a category
  - no nuance or concept of how sure we are about the category
  - line
  - 0 or 1
soft threshold:
  - curve
  - adds nuance
  - any value between 0 and 1 inclusive
Support Vector Machines:
  - a "machine" designed to find the maximum margin separator
  - We want this since a lot of lines, decision boundaries that can be drawn
maximum margin separator:
  - boundary that maximizes the distance between any of the data points
regression:
  - supervised learning task of learning a function mapping an input point to a continuous value
Evaluating Hypotheses:
  - can think of this as an optimization problem where we want to minimize a loss function
loss function:
  - function that expresses how poorly our hypothesis performs
0-1 loss function:
  - L(actual,predicted) =:
      - 0 if actual = predicted,
      - 1 otherwise
L_{1} loss function:
  - L(actual, predicted) = |actual - predicted|
L_{2} loss function:
  - L(actual, predicted) = (actual-predicted)^{2}
overfitting:
  - a model that fits too closely to a particular data set and therefore may fail to generalize to future data
  - this is a risk if the only thing we care about is minimizing the loss function
regularization:
  - penalizing hypotheses that are ore complex to favor simpler, more general hypotheses
  - cost(h) = loss(h) + λ × complexity(h)
can also run experiments by seeing if we're overfitting:
holdout cross-validation:
  - splitting data into a training set and a test set, such that learning happens on the training set and is evaluated on the test set
k-fold cross validation:
  - splitting data into k sets, and experimenting k times, using each set as a test set once, and using remaining data a training set
scikit-learn:
  - python library
reinforcement learning:
  - given a set of rewards or punishments, learn what actions to take in the future
  - An agent in some environment starts out in a state. The agent commits an action and is given a new state by/in the environment and a reward for the action
  - reward could be big or small, positive, negative
Markov Decision Process:
  - model for decision-making, representing states, actions, and their rewards
  - Set of states S
  - Set of actions ACTIONS(s)
  - Transition model P(s'|s,a):
      - probability of state s` given action a taken at state state
  - Reward function R(s,a,s')
Q-learning:
  - method for learning a function Q(s,a), estimate of the value of performing action a in state s
  - overview:
      - Start with Q(s,a) = 0 fro all s,action
      - When we taken an action and receive a reward:
          - Estimate the value of Q(s,a) based on current reward and expected future rewards
          - Update Q(s,a) to take into account old estimate as well as our new estimate
  - Q-Learning:
      - Start with Q(s,a) = 0 for all s,action
      - ? Every time we take an action a in state s and observe a reward r, we update
        : - Q(s,a) ← Q(s,a) + α(new value estimate - old value estimate)
          - Q(s,a) ← Q(s,a) + α(new value estimate - Q(s,a))
          - Q(s,a) ← Q(s,a) + α((r + future reward estimate) - Q(s,a))
          - Q(s,a) ← Q(s,a) + α((r + MAX_{a'}Q(s',a')) - Q(s,a))
          - Q(s,a) ← Q(s,a) + α((r + γMAX_{a'}Q(s',a')) - Q(s,a))
Greedy Decision-Making:
  - When in sate s, choose action a with highest Q(s,a)
Explore vs. Exploit:
ε-greedy:
  - Set ε equal to how often we want to move randomly.
  - With probability 1 - ε choose the estimated best move.
  - With probability ε, choose a random move.
function approximation:
  - approximating Q(s,a), often by a function combining various features, rather than storing one value for every state-action pair
unsupervised learning:
  - given input data without any additional feedback, learn patterns
clustering:
  - organizing a set of objects into groups in such a way that similar objects tend to be in the same groups
  - some clustering applications:
      - genetic research
      - image segmentation
      - market research
      - medical imaging
      - social network analysis
k-means clustering:
  - algorithm for clustering data based on repeatedly assigning points to clusters and updating those clusters' centers
Learning:
  - supervised learning
  - reinforcement learning
  - unsupervised learning